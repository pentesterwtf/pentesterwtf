<!doctype html><html><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>Risk Intelligence - Pentester, wtf!?</title><meta name=viewport content="width=device-width,initial-scale=1"><meta property="og:title" content="Risk Intelligence"><meta property="og:description" content="Alternatively: A pentester reads a book on Risk by Dylan Evans"><meta property="og:type" content="article"><meta property="og:url" content="/blog/2020/risk-intelligence/"><meta property="article:published_time" content="2020-10-27T18:00:00+10:00"><meta property="article:modified_time" content="2020-10-27T18:00:00+10:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Risk Intelligence"><meta name=twitter:description content="Alternatively: A pentester reads a book on Risk by Dylan Evans"><link href="https://fonts.googleapis.com/css?family=Ubuntu:300,400,300italic,400italic|Raleway:500,100,300" rel=stylesheet><link rel=stylesheet type=text/css media=screen href=/css/normalize.css><link rel=stylesheet type=text/css media=screen href=/css/main.css></head><body><div class="container wrapper post"><div class=header><a href=/><img src=/images/header.png alt="Break things, write reports"></a><div class=site-description></div><nav class=nav><ul class=flat><li><a href=/>home</a></li><li><a href=/categories/>Categories</a></li><li><a href=/tags/>Tags</a></li></ul></nav></div><div class=post-header><h1 class=title>Risk Intelligence</h1><h3><blockquote>Alternatively: A pentester reads a book on Risk by Dylan Evans</blockquote></h3><div class=meta>Tags &mdash; |
<a href=/tags/Book/>Book</a> |
Categories: &mdash;
<a href=/categories/Book/>Book</a> |</div><div class=meta>Posted at &mdash; Oct 27, 2020</div></div><div class=markdown><p>Sometimes I read.</p><p>Most of the time, it&rsquo;s books that <em>might</em> apply to my job, my hobbies, or in some way could be useful, or perhaps someone recommended me a book and I&rsquo;ve forgotten what utility it may have had. Unfortunately, as I do not track <em>who</em> recommended the book, I don&rsquo;t have any idea on who to thank or blame.</p><p>I recently read Risk Intelligence: How to live with uncertainty by Dylan Evans (<a href=https://www.amazon.com.au/Risk-Intelligence-How-Live-Uncertainty/dp/1451610912),>https://www.amazon.com.au/Risk-Intelligence-How-Live-Uncertainty/dp/1451610912),</a> which was about making meaningful and informed decisions around thinks which involve risk; i.e. Do I buy insurance for my iPhones screen in case it is dropped.</p><p>I&rsquo;m unsure if it was good book, but it did give me a few ideas.</p><h2 id=a-day-at-the-races>A day at the races</h2><ul><li>The book starts off by citing a study by Stephen Ceci and Jeffrey Liker (Ref is 10.1037/0096-3445.115.3.255, thanks <a href=https://sci-hub.se>https://sci-hub.se</a>) about people putting bets on horses.</li><li>They were mostly the kinds of people you&rsquo;d imagine sit around betting on horses during the day back in 1986</li><li>People were interviewed and asked to bet on horses, while the authors compared these bets against outcomes<ul><li>They also asked about hypothetical races too, but that&rsquo;s not as exciting for the point</li></ul></li></ul><p>Unsurprisingly, the study is called &ldquo;A Day at the races: A Study of IQ, Expertise and Cognitive complexity&rdquo;, and found that IQ was unrelated skilled performance at the racetrack (i.e. picking the right horse).</p><p>The authors went on to explain that the people better at betting were taking into consideration a number of factors, and had an idea of which ones to weigh more than others.</p><h2 id=risk-matrix>Risk Matrix</h2><p>This actually seemed pretty applicable to $DayJob, I quote the following:</p><pre><code>[...] I was in the company's head office, meeting with the risk management team.
It turned out that they had been using a popular risk management methodology that
involved first estimating the liklihood and impact of each risk on a simple three-point
scale (low, medium, high). Next, the likelihood and impact of each risk were plotted on
a so-called risk risk matrix in which different regions were defined as high, medium, or low risk
</code></pre><p>For those who haven&rsquo;t seen, he&rsquo;s describing something that looks like the following:</p><p><img src=/img/risk-nonsense.jpg alt="Bullshit table"></p><p>You&rsquo;ve probably seen the same thing, if you&rsquo;re not using something like CVSS (<a href=https://www.first.org/cvss/>https://www.first.org/cvss/</a>) you or your clients are probably doing something like the above.</p><p>These are mostly bullshit, and are unlikely to be too helpful - but as penetration testers our job is not to understand risk, just point out issues in some meaningful fashion.</p><p>Awkwardly, clients would state that the risk ratings given to them are by risk professionals, but penetration testers are not that, not are most Governnance, Risk and Compliance (GRC) experts.</p><p>Anyway, to continue with the quote:</p><pre><code>Such scoring methods are relatively easy to create and teach. Consequently,
they have become very popular in a wide variety of business sectors.
Respected organisations have designed such methods and represent them
as best practices for thousands of users. For example, the US Army have 
developed a weighted scoring-based method for evaluating the risk of missions.
The US Department of Health and Human Services uses a weighted scoring method
to determine vaccine allocations in the event of a pandemic outbreak, and NASA
uses a scoring method for assessments of risk in manned and unmaned missions.

</code></pre><p>Unsurprising that most places have <em>something</em> for these kinds of things, however:</p><pre><code>I believe that these scoring methods are deeply flawed for many reasons. The
first and most fundamental problem is that they are only understood as the 
initial estimates that serve as input, if you put garbage in, you get garbage
out. The initial estimates are usually provided by experts, but even experts
suffer from systemic errors and biases when estimating probabilities. 
Furthermore, these methods fudge matters by using verbal scales in which risks
are characterised as &quot;low&quot;, &quot;medium&quot; and &quot;high&quot; instead of asking users to 
state numeric probabilities.
</code></pre><p>I agree in part about this kind of thing, however I&rsquo;m unsure how to put a percentage likelyhood on someone exploiting cross site scripting.
As stated above, with these risk matrices, we end up with fairly nonsense &ldquo;verbal&rdquo; scales.</p><p>He also points out the problem around how experts could just put garbage data in due to systemic errors and biases when estimating, i.e. &ldquo;How skilled the average attacker is&rdquo;.</p><p>For $DayJob, It might be more meaningful to talk about the likelihood of anyone caring about a particular application, if it&rsquo;s on the internet, however this would probably end up in another broken framework. However, it should be noted that someone probably knew a bunch of systems sucked, then said systems achieved media attention, then were hacked subsequently.</p><p>Notably we could talk about recent US events, such as <a href=https://www.govtech.com/security/Anonymous-Claims-Responsibility-for-Minneapolis-PD-Cyberattack.html>https://www.govtech.com/security/Anonymous-Claims-Responsibility-for-Minneapolis-PD-Cyberattack.html</a>. If anyone saw the systems, they&rsquo;d probably know it was only a matter of time, and with enough attention, someone eventually cared enough to do something. Generally we call these Issue Motivated Groups :)</p><p>Quoting the rest of the relevant bits would be tedious, but his approach from here was:</p><ul><li>Get people to state actual numbers, i.e.<ul><li>10% chance we&rsquo;ll get hacked this month (But no number on impact)</li><li>10% chance we&rsquo;ll lose 2 million dolars of inventory</li></ul></li><li>They&rsquo;d review these numbers every month, and adjust their expectations on probability</li><li>With numbers, people were able to have better resolution on what mattered</li><li>With the review process, they also were able to have a faster feedback loop on processes</li></ul><p>This aimed more towards project blowouts and better outcomes, but a security impact could reasonably be treated in a similar fashion, albiet the numbers could be guessing.</p><h2 id=the-availability-hueristic>The Availability hueristic</h2><p>Another bit was <em>very</em> relevant to $DayJob, which was working through a list of biases that affect how we make up probability numbers. The most interesting one was the availability bias, which could be summarised off wikipedia shamelessly as follows:</p><pre><code>The availability heuristic, also known as availability bias, is a mental 
shortcut that relies on immediate examples that come to a given person's
 mind when evaluating a specific topic, concept, method or decision.
</code></pre><p>This can come up often when scoping out likely paths to victory for penetration testers:</p><ul><li>What worked on your last gig is probably what you&rsquo;ll try again</li><li>If you haven&rsquo;t had SQL injection in years, and forgotten about it, you might not look for it</li></ul><p>His solution was around considering the probability of dramatic events, so it probably wasn&rsquo;t too relevant in testing methodologies, but might be more valuable
when considering how likely it is for an organisation to be completely owned by a bug, and if you have recently seen it in the news or not.</p><h2 id=meta-spicy-bits>Meta: Spicy bits</h2><p>A lot of this book seems to come down to not using weasly words unintentionally (or otherwise, if you&rsquo;re naughty), to signal how sure you are on something happening. &ldquo;Likely&rdquo; could mean anything from 50-70% for one person, but your audience could think that means 90%. There was a bunch of citations around this in legal precidence, of &ldquo;beyond reasonable doubt&rdquo; and &ldquo;balance of probabilities&rdquo;, and times where the jury (i.e. non-experts asked to use expert language), did not have the same understanding as experts (i.e. the lawyers and judge), often to horrific effect.</p><p>There was a very spicy comment around how short sellers provide a useful corrective to epidemics of optism bias, which was in context of the global finacial crisis. Related, this is also applicable to our job as breakers to find weird things and not expect them to be fine.</p><p>The book goes into some ideas of mathematical models, cites some more things around cases where models are making people millions when gambling in Hong Kong, but also concedes that &ldquo;true risk intelligence is not achieved simply by mathematical calculations&rdquo;.</p><p>Theres a few mandatory references to unknown unknowns, Anton-Babinski Syndrome and Dunning-Kruger.</p><h2 id=meta-citations>Meta: Citations</h2><p>About a third of the book is references and citations, a lot of which I skimmed and they seemed to be:</p><ul><li>Peer reviewed</li><li>Cited a lot</li><li>Published with reputable places</li><li>Actually said the same thing he said</li></ul><p>I&rsquo;m not an academic, so that&rsquo;s probably about as good as I can get for filtering academic papers.</p><h2 id=meta-what-i-should-have-done-instead>Meta: What I should have done instead</h2><p>Practically, this book was pretty useless. It cited a bunch of things that most people are unlikely to follow, and just kept throwing comment after comment on different studies, but again as a non-expert in that field, it wasn&rsquo;t terribly useful. It&rsquo;s also unclear how to apply any of this.</p><p>Next time I might just go straight to Algorithms to Live by (<a href=https://www.amazon.com.au/Algorithms-Live-Computer-Science-Decisions/dp/0007547994>https://www.amazon.com.au/Algorithms-Live-Computer-Science-Decisions/dp/0007547994</a>) , as it&rsquo;s probably more actionable in my $DayJob</p><h2 id=addendum>Addendum</h2><p>After mentioning this book to a friend and trying to summarise pieces, a few pages on Bayesian probability popped up which would have been good, had the book actually made a better point of it. We could probably use this for $DayJob, but it&rsquo;s not clear how due to this book.</p></div></div><div class="footer wrapper"><nav class=nav><div></div></nav></div><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-141761824-1','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script></body></html>